# 聴覚ストリーミング実験システム

## 概要

このプロジェクトは、音のパターンの違いを検出する能力を測定するためのWeb実験システムです。特に「聴覚ストリーム分凝（ストリーミング）」現象に焦点を当てています。実験では、周波数とタイミングが変化する一連の聴覚刺激（「ギャロップ」と呼ばれる）を参加者に提示し、妨害音の中からターゲット音を識別するよう求めます。

システムは適応的階段法（アダプティブ・ステアケース）を使用して、異なる周波数条件における参加者の知覚閾値を効率的に決定します。実験が進むにつれて、参加者のパフォーマンスに基づいて難易度が調整され、不正解の後は簡単になり、連続して正解した後は難しくなります。

研究者はこのシステムを使用して、周波数分離が聴覚知覚、特にリズムパターンの識別にどのように影響するかについてのデータを収集します。システムは参加者登録から試行提示、データ収集、統計分析、結果の可視化まで、実験プロセス全体を自動化します。

## プロジェクト構成

### コアシステムとサービス

1. **Webアプリケーション（Flask）**: すべてのHTTPリクエスト、セッション管理、実験ロジックを処理するメインサーバーアプリケーション。
2. **階段法プロシージャ**: 参加者のパフォーマンスに基づいて試行の難易度を調整する適応型テストアルゴリズム。
3. **音声刺激提示**: 参加者に連続した音を提示するシステム。
4. **データ収集と保存**: 参加者の反応を記録し、CSVファイルとして保存するメカニズム。
5. **統計分析**: 最尤推定法（MLE）を使用した実験後の処理による知覚閾値の計算。
6. **データ可視化**: 刺激強度と知覚の関係を示す心理測定関数プロットの生成。

### メインファイルとディレクトリ

- **`app.py`**: ルーティング、セッション管理、実験ロジックを処理するメインFlaskアプリケーション。
- **`templates/`**: 異なる実験段階のHTMLテンプレートを含むディレクトリ：
  - **`index.html`**: 参加者データが収集される初期設定ページ。
  - **`practice.html`**: 参加者がタスクに慣れるための練習セッション。
  - **`experiment.html`**: 試行が提示されるメイン実験インターフェース。
  - **`break_page.html`**: 実験ブロック間に表示されるページ。
  - **`complete.html`**: 実験完了後に表示される結果ページ。
- **`static/`**: 静的アセットを含むディレクトリ：
  - **`css/styles.css`**: すべてのHTMLテンプレートのスタイリング。
  - **`stimuli/`**: 実験用の音声ファイル。
  - **`sample_fig/`**: 生成された図形と視覚化。
- **`analysis_MLE_v2.py`**: 実験データに対して最尤推定分析を実行するモジュール。
- **`fig_compare.R`**: 異なる周波数条件間で結果を比較するためのRスクリプト。
- **`requirements.txt`**: アプリケーションを実行するために必要なPython依存関係。

### メイン機能/クラス

1. **セッション管理機能**:
   - `start_experiment()`: 参加者データに基づいて実験セッションを初期化します。
   - `initialize_condition_session()`: 各周波数条件のパラメータを設定します。
   - `set_data_file_path()`: データファイルを保存するためのパスを確立します。

2. **実験ロジック機能**:
   - `next_trial()`: 現在のパラメータに基づいて次の試行のデータを生成します。
   - `submit_response()`: 参加者の反応を処理し、パラメータを更新します。
   - `next_block()`: 次の周波数条件に移行します。
   - `complete()`: 最終分析を実行し、結果を生成します。

3. **階段法プロシージャ機能**:
   - `decide_step_size()`: パフォーマンスに基づいて難易度をどの程度調整するかを決定します。

4. **分析機能**:
   - `perform_mle_analysis()`: 心理測定関数のパラメータを推定するためにMLEを適用します。
   - `calc_threshold()`: フィットされたモデルから75%検出閾値を計算します。

## セットアップと実行方法

1. リポジトリをクローンします:
   ```
   git clone https://github.com/Takaya46/sound_exp_stream_segregation.git
   cd sound_exp_stream_segregation
   ```

2. 依存関係をインストールします:
   ```
   pip install -r requirements.txt
   ```

3. Flaskアプリケーションを実行します:
   ```
   python app.py
   ```

4. ブラウザで`http://localhost:5000`にアクセスして実験を開始します。

## 使用方法

1. トップページで参加者IDと実験条件を入力します。
2. 練習セッションを完了して、タスクに慣れます。
3. メイン実験では、3つの音を聞いて、どの音（1番目または3番目）がターゲット音かを識別します。
4. Fキー（1番目の音がターゲット）またはJキー（3番目の音がターゲット）を押して反応します。
5. スペースキーを押して次の試行に進みます。
6. すべてのブロックが完了すると、結果が分析され、心理測定曲線が表示されます。

## コードベース特有の用語集

- **オフセット**: ターゲットと妨害音の間の時間差（ミリ秒単位）
- **階段法プロシージャ**: 参加者の反応に基づいて難易度を調整する適応型テスト方法
- **反転**: 難易度調整の方向が変わるポイント（ステップサイズの調整に使用）
- **ブロック**: 同じ周波数条件を持つ試行のグループ
- **試行**: 参加者の反応を必要とする刺激の単一提示
- **ターゲット音**: 参加者が識別する必要があるギャップを含む音
- **通常音**: ギャップのない標準音（妨害音として使用）
- **周波数条件**: ターゲットとマスクの間の異なる周波数関係（g_base、g_1octave など）
- **MLE**: 知覚閾値を推定するための統計的手法である最尤推定法
- **心理測定曲線**: 刺激強度と正答確率の関係を示すグラフ
